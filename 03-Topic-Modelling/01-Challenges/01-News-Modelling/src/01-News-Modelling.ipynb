{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01-News-Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1495020689067-958852a7765e?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)\n",
    "\n",
    "Photo by [Roman Kraft](https://unsplash.com/photos/_Zua2hyvTBk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise is about modelling the main topics of a database of News headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by importing the needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import needed libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LsiModel\n",
    "from gensim.models import LdaModel\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data in the file `random_headlines.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: load the dataset\n",
    "df = pd.read_csv('random_headlines.csv',on_bad_lines='skip')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is always a good idea to perform some EDA on a dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   publish_date   20000 non-null  int64 \n",
      " 1   headline_text  20000 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 312.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# TODO: Perform a short EDA\n",
    "df.info()\n",
    "# pas de valeur null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['publish_date', 'headline_text'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         ute driver hurt in intersection crash\n",
       "1                  6yo dies in cycling accident\n",
       "2                 bumper olive harvest expected\n",
       "3            replica replaces northernmost sign\n",
       "4                  woods targets perfect season\n",
       "5    leckie salvages dramatic draw for adelaide\n",
       "Name: headline_text, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## voir les plots histos de V.MALARA sur des donn√©es textuelles\n",
    "df.headline_text[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform all the needed preprocessing on those headlines: case lowering, tokenization, punctuation removal, stopwords removal, stemming/lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [ute, driver, hurt, intersect, crash]\n",
       "1                        [die, cycl, accid]\n",
       "2           [bumper, oliv, harvest, expect]\n",
       "3     [replica, replac, northernmost, sign]\n",
       "4           [wood, target, perfect, season]\n",
       "5    [lecki, salvag, dramat, draw, adelaid]\n",
       "6        [group, gaug, rail, servic, futur]\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Preprocess the input data\n",
    "stemmer = PorterStemmer()\n",
    "def processing(document):\n",
    "    tokens = word_tokenize(document)\n",
    "    tokens = [t.lower() for t in tokens if t.isalpha()]\n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    tokens = [stemmer.stem(t) for t in tokens]\n",
    "    return tokens\n",
    "\n",
    "df['tokens'] = df.headline_text.apply(processing)\n",
    "df.tokens[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a corpus\n",
    "corpus = df['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the dictionary: this is a dictionary mapping words and their corresponding numbers for later visualisation\n",
    "id2word = Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use Gensim to compute a BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute the BOW using Gensim\n",
    "# Create a BOW\n",
    "bow = [id2word.doc2bow(line) for line in corpus]  # convert corpus to BoW format\n",
    "print(bow[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the TF-IDF using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute TF-IDF\n",
    "# Instanciate a TF-IDF\n",
    "tfidf_model = TfidfModel(bow)\n",
    "\n",
    "# Compute the TF-IDF\n",
    "tf_idf_gensim = tfidf_model[bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.30725466582280214),\n",
       " (1, 0.3528943781678455),\n",
       " (2, 0.42129048115131124),\n",
       " (3, 0.5992666854471201),\n",
       " (4, 0.49442279315598586)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_gensim[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally compute the **LSA** (also called LSI) using Gensim, for a given number of Topics that you choose yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '-0.455*\"man\" + -0.389*\"polic\" + -0.324*\"charg\" + -0.146*\"murder\" + '\n",
      "  '-0.146*\"court\" + -0.131*\"face\" + -0.112*\"new\" + -0.112*\"miss\" + '\n",
      "  '-0.109*\"crash\" + -0.107*\"death\"'),\n",
      " (1,\n",
      "  '0.396*\"second\" + 0.334*\"abc\" + 0.329*\"news\" + -0.305*\"man\" + '\n",
      "  '0.284*\"weather\" + 0.228*\"busi\" + -0.216*\"charg\" + 0.163*\"sport\" + '\n",
      "  '0.139*\"plan\" + 0.124*\"council\"'),\n",
      " (2,\n",
      "  '-0.372*\"second\" + -0.318*\"man\" + -0.296*\"abc\" + -0.261*\"news\" + '\n",
      "  '-0.257*\"weather\" + -0.242*\"charg\" + 0.195*\"plan\" + 0.169*\"govt\" + '\n",
      "  '0.167*\"council\" + -0.152*\"busi\"'),\n",
      " (3,\n",
      "  '0.765*\"polic\" + -0.234*\"man\" + -0.230*\"charg\" + 0.164*\"investig\" + '\n",
      "  '0.141*\"probe\" + -0.131*\"council\" + -0.122*\"plan\" + -0.119*\"court\" + '\n",
      "  '-0.111*\"face\" + 0.106*\"search\"'),\n",
      " (4,\n",
      "  '0.394*\"kill\" + 0.319*\"crash\" + 0.279*\"fire\" + -0.215*\"charg\" + '\n",
      "  '-0.182*\"council\" + 0.172*\"car\" + -0.171*\"court\" + -0.161*\"polic\" + '\n",
      "  '0.158*\"rural\" + -0.157*\"plan\"')]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute LSA\n",
    "lsi = LsiModel(tf_idf_gensim, id2word=id2word, num_topics=5)\n",
    "\n",
    "pprint(lsi.print_topics())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the topic, show the most significant words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the 3 or 4 most significant words of each topic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think about those results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic 0 only has topics not showing up in the docs with negative LSA coefs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to use LDA instead of LSA using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute LDA\n",
    "# Compute the LDA\n",
    "lda1 = LdaModel(corpus=tf_idf_gensim, num_topics=5, id2word=id2word, passes=10, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:  0.005*\"countri\" \n",
      "1:  0.007*\"man\" \n",
      "2:  0.005*\"plan\" \n",
      "3:  0.007*\"murder\" \n",
      "4:  0.006*\"second\" \n"
     ]
    }
   ],
   "source": [
    "# TODO: print the most frequent words of each topic\n",
    "# Print the main topics\n",
    "for idx in range(0,len(lda1.print_topics())):\n",
    "    print(str(idx) + ':  ' + lda1.print_topics()[idx][1].split('+')[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, how does it work with LDA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some visualization of the LDA results using pyLDAvis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: show visualization results of the LDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on your results, you can try to fine tune the algorithm: number of topics, hyperparameters...\n",
    "And check with others their results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
