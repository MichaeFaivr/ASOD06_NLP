{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vivabot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1527430253228-e93688616381?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1191&q=80)\n",
    "\n",
    "Photo by [Rock'n Roll Monkey](https://unsplash.com/photos/R4WCbazrD1g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will build your own bot: Vivabot. To do so, we will apply our knowledge about text preprocessing, TF-IDF and similarity, but also basic Python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by importing the needed libraries:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12:10 start Vivabot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's load our sentence database, stored in the file *chatbot_database.txt* and have a look at the data.\n",
    "\n",
    "Warning, the file is not a CSV, so you might need to play with the paramaters of `pd.read_csv()` to open it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: load chatbot_database.txt\n",
    "##df = pd.read_csv('chatbot_database.txt', delimiter='\\\\', header=None)\n",
    "df = pd.read_csv('chatbot_database.txt', sep='\\\\', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0], dtype='int64')"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # pas de colonne car header=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 1)"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A chatbot (also known as a talkbot, chatterbot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Such programs are often designed to convincing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chatbots are typically used in dialog systems ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Some chatterbots use sophisticated natural lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The term \"ChatterBot\" was originally coined by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>These cloud platforms provide Natural Language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>There are many APIs available for building you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Malicious chatbots are frequently used to fill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>They are commonly found on Yahoo! Messenger, W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>There has also been a published report of a ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0   A chatbot (also known as a talkbot, chatterbot...\n",
       "1   Such programs are often designed to convincing...\n",
       "2   Chatbots are typically used in dialog systems ...\n",
       "3   Some chatterbots use sophisticated natural lan...\n",
       "4   The term \"ChatterBot\" was originally coined by...\n",
       "..                                                ...\n",
       "81  These cloud platforms provide Natural Language...\n",
       "82  There are many APIs available for building you...\n",
       "83  Malicious chatbots are frequently used to fill...\n",
       "84  They are commonly found on Yahoo! Messenger, W...\n",
       "85  There has also been a published report of a ch...\n",
       "\n",
       "[86 rows x 1 columns]"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df ## on n'a pas les lignes vides ... comment regrouper les blocs de texte ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A chatbot (also known as a talkbot, chatterbot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Such programs are often designed to convincing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chatbots are typically used in dialog systems ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Some chatterbots use sophisticated natural lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The term \"ChatterBot\" was originally coined by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>These cloud platforms provide Natural Language...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>There are many APIs available for building you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Malicious chatbots are frequently used to fill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>They are commonly found on Yahoo! Messenger, W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>There has also been a published report of a ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text\n",
       "0   A chatbot (also known as a talkbot, chatterbot...\n",
       "1   Such programs are often designed to convincing...\n",
       "2   Chatbots are typically used in dialog systems ...\n",
       "3   Some chatterbots use sophisticated natural lan...\n",
       "4   The term \"ChatterBot\" was originally coined by...\n",
       "..                                                ...\n",
       "81  These cloud platforms provide Natural Language...\n",
       "82  There are many APIs available for building you...\n",
       "83  Malicious chatbots are frequently used to fill...\n",
       "84  They are commonly found on Yahoo! Messenger, W...\n",
       "85  There has also been a published report of a ch...\n",
       "\n",
       "[86 rows x 1 columns]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['Text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nquotes = []\\nfor row in df.Text:\\n    quote = \"\"\\n    print(f\\'row: {row}\\')\\n    if row == \\'\\':\\n        quotes.append(quote)\\n    quote += \\'\\n\\' + row\\nquotes\\n'"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the list of quotes : essai pour regrouper les blocs de texte séparés par les lignes vides\n",
    "\"\"\"\n",
    "quotes = []\n",
    "for row in df.Text:\n",
    "    quote = \"\"\n",
    "    print(f'row: {row}')\n",
    "    if row == '':\n",
    "        quotes.append(quote)\n",
    "    quote += '\\n' + row\n",
    "quotes\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is necessary to compute the TF-IDF on this database. First, do not forget to preprocess the data, and then compute and store the TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: preprocess and compute the TF-IDF of this database\n",
    "def preprocessing(document):\n",
    "    # 1- tokenization\n",
    "    tokens = word_tokenize(document)\n",
    "    # 2- lower case on alpha and leave unchaged others\n",
    "    ###tokens = [t.lower() if t.isalpha() else t for t in tokens] ## pb sur similarity.max(): à voir\n",
    "    # 3- remove stopwords and punctuation\n",
    "    ##stop_words = set(stopwords.words('english') + list(string.punctuation))\n",
    "    ###tokens = [t for t in tokens if not t in stop_words]\n",
    "    # 4- stemming\n",
    "    stemmer = PorterStemmer() #build root by removing some known suffix and prefix\n",
    "    tokens_stem = [stemmer.stem(w) for w in tokens]\n",
    "    return tokens_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply preproc to df\n",
    "df['Text_preproc'] = df['Text'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF sur les données pré-processées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>100</th>\n",
       "      <th>16</th>\n",
       "      <th>1950</th>\n",
       "      <th>1966</th>\n",
       "      <th>1972</th>\n",
       "      <th>1984</th>\n",
       "      <th>1994</th>\n",
       "      <th>2006</th>\n",
       "      <th>2008</th>\n",
       "      <th>...</th>\n",
       "      <th>worker</th>\n",
       "      <th>workings</th>\n",
       "      <th>would</th>\n",
       "      <th>written</th>\n",
       "      <th>xico</th>\n",
       "      <th>yahoo</th>\n",
       "      <th>yekaliva</th>\n",
       "      <th>yet</th>\n",
       "      <th>york</th>\n",
       "      <th>zuckerberg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.282888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253146</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 718 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    000  100   16  1950  1966  1972  1984      1994  2006  2008  ...  worker  \\\n",
       "0   0.0  0.0  0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  ...     0.0   \n",
       "1   0.0  0.0  0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  ...     0.0   \n",
       "2   0.0  0.0  0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  ...     0.0   \n",
       "3   0.0  0.0  0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  ...     0.0   \n",
       "4   0.0  0.0  0.0   0.0   0.0   0.0   0.0  0.282888   0.0   0.0  ...     0.0   \n",
       "..  ...  ...  ...   ...   ...   ...   ...       ...   ...   ...  ...     ...   \n",
       "81  0.0  0.0  0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  ...     0.0   \n",
       "82  0.0  0.0  0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  ...     0.0   \n",
       "83  0.0  0.0  0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  ...     0.0   \n",
       "84  0.0  0.0  0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  ...     0.0   \n",
       "85  0.0  0.0  0.0   0.0   0.0   0.0   0.0  0.000000   0.0   0.0  ...     0.0   \n",
       "\n",
       "    workings     would  written  xico     yahoo  yekaliva  yet  york  \\\n",
       "0        0.0  0.000000      0.0   0.0  0.000000       0.0  0.0   0.0   \n",
       "1        0.0  0.243849      0.0   0.0  0.000000       0.0  0.0   0.0   \n",
       "2        0.0  0.000000      0.0   0.0  0.000000       0.0  0.0   0.0   \n",
       "3        0.0  0.000000      0.0   0.0  0.000000       0.0  0.0   0.0   \n",
       "4        0.0  0.000000      0.0   0.0  0.000000       0.0  0.0   0.0   \n",
       "..       ...       ...      ...   ...       ...       ...  ...   ...   \n",
       "81       0.0  0.000000      0.0   0.0  0.000000       0.0  0.0   0.0   \n",
       "82       0.0  0.000000      0.0   0.0  0.000000       0.0  0.0   0.0   \n",
       "83       0.0  0.000000      0.0   0.0  0.000000       0.0  0.0   0.0   \n",
       "84       0.0  0.000000      0.0   0.0  0.253146       0.0  0.0   0.0   \n",
       "85       0.0  0.000000      0.0   0.0  0.000000       0.0  0.0   0.0   \n",
       "\n",
       "    zuckerberg  \n",
       "0          0.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "..         ...  \n",
       "81         0.0  \n",
       "82         0.0  \n",
       "83         0.0  \n",
       "84         0.0  \n",
       "85         0.0  \n",
       "\n",
       "[86 rows x 718 columns]"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TF-IDF entraîné sur tout le corpus\n",
    "## !!! OK avec le preproc de base de sklearn sur col: 'Text' pour la fonction: get_closest_sentence() !!!\n",
    "TFIDF_vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))\n",
    "TF_IDF = TFIDF_vectorizer.fit_transform(df.Text).toarray()\n",
    "\n",
    "### NOK avec df.Text_preproc dans le calcul de similarity; tjs max == 0.0 qd j'utilise t.lower() if t.isalpha() !!!??? A voir\n",
    "## OK avec non-utilisation de la partie: t.lower() if t.isalpha() mais résultats moins bien qu'avec df.Text\n",
    "#TFIDF_vectorizer = TfidfVectorizer(analyzer=lambda x: x)\n",
    "#TF_IDF = TFIDF_vectorizer.fit_transform(df.Text_preproc).toarray()\n",
    "TF_IDF\n",
    "\n",
    "# Visu avec le df de tf_idf\n",
    "df_TFIDF = pd.DataFrame(data=TF_IDF, columns=TFIDF_vectorizer.get_feature_names_out())\n",
    "df_TFIDF #86 x 639"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fonction en vue de la 'généralisation' de la fonction vivabot avec le fichier 'database' dans la signature\n",
    "def read_data_preproc_dataframe(database):\n",
    "    # database is a txt file\n",
    "    # in the same rep as the code to make it easier\n",
    "    df = pd.read_csv(database, sep='\\\\', header=None)\n",
    "\n",
    "    df.columns = ['Text']\n",
    "    df['Text_preproc'] = df['Text'].apply(preprocessing) ## pas utilisé en fait\n",
    "    print(df)\n",
    "    print(f'df.shape: {df.shape}')\n",
    "\n",
    "    ## TF-IDF entraîné sur tout le corpus\n",
    "    ## !!! OK avec le preproc de base de sklearn sur col: 'Text' pour la fonction: get_closest_sentence() !!!\n",
    "    TFIDF_vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'))\n",
    "    TF_IDF = TFIDF_vectorizer.fit_transform(df.Text).toarray()\n",
    "\n",
    "    return TFIDF_vectorizer, TF_IDF, df.Text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to get the closest sentence compared to a user query, using cosine similarity. This will be computed in the method `get_closest_sentence(query, tf_idf, vectorizer)`. This method will return the index of the closest sentence of `query` within the TF-IDF of the database, using `vectorizer` to compute the TF-IDF of the query.\n",
    "\n",
    "Do not forget to preprocess the query before computing the TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement get_closest_sentence(query, tf_idf, vectorizer)\n",
    "# voir EXO-3\n",
    "\"\"\"\n",
    "- Objet: calculer la phrase du corpus la + proche de la query\n",
    "- Input: query = liste avec une string\n",
    "- Return: phrase la + proche sur la base de la similarité cosine\n",
    "\"\"\"\n",
    "def get_closest_sentence(query, tf_idf, vectorizer, df_text):\n",
    "    closest_sentence = \"\"\n",
    "    query_TFIDF = vectorizer.transform(query).toarray()\n",
    "    #print(pd.DataFrame(data=query_TFIDF, columns=TFIDF_vectorizer.get_feature_names_out()))\n",
    "\n",
    "    # cosine similarity between the query and the movies\n",
    "    similarity = cosine_similarity(query_TFIDF, tf_idf)\n",
    "\n",
    "    #print(f\"Similarity.max(): {similarity.max()}\") #MAX = 0.0 dans les tests\n",
    "    #print(f'similarity.shape: {similarity.shape}')\n",
    "    #print(f'similarity.argmax(): {similarity.argmax()}')\n",
    "\n",
    "    ## PASSER df.Text en arg !!!\n",
    "    #closest_sentence = df.Text[similarity.argmax()]\n",
    "    closest_sentence = df_text[similarity.argmax()]\n",
    "    print(f\"phrase la + proche de ** {query[0]} **:\\n {closest_sentence}\")\n",
    "    return similarity.max(), closest_sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrase la + proche de ** Do you think chatbots are really intelligent? **:\n",
      " However Weizenbaum himself did not claim that ELIZA was genuinely intelligent, and the Introduction to his paper presented it more as a debunking exercise:\n",
      "phrase la + proche de ** '%' of companies using chatbots **:\n",
      " A 2017 study showed 4% of companies used chatbots.\n",
      "phrase la + proche de ** 2017 chatbots **:\n",
      " A 2017 study showed 4% of companies used chatbots.\n",
      "phrase la + proche de ** According to Forrester (2015) **:\n",
      " According to Forrester (2015), AI will replace 16 percent of American jobs by the end of the decade.\n",
      "phrase la + proche de ** Aeromexico airline chatbot **:\n",
      " Aeromexico airline chatbot running on Facebook Messenger, March 2018\n",
      "phrase la + proche de ** field of AI research is natural **:\n",
      " One pertinent field of AI research is natural language processing.\n",
      "phrase la + proche de ** which is specific conversational agent. **:\n",
      " uses a markup language called AIML, which is specific to its function as a conversational agent, and has since been adopted by various other developers of, so called, Alicebots.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Do you think chatbots are really intelligent?': ['However Weizenbaum himself did not claim that ELIZA was genuinely intelligent, and the Introduction to his paper presented it more as a debunking exercise:',\n",
       "  0.24132947726326626],\n",
       " \"'%' of companies using chatbots\": ['A 2017 study showed 4% of companies used chatbots.',\n",
       "  0.3362248410272699],\n",
       " '2017 chatbots': ['A 2017 study showed 4% of companies used chatbots.',\n",
       "  0.5144475319394324],\n",
       " 'According to Forrester (2015)': ['According to Forrester (2015), AI will replace 16 percent of American jobs by the end of the decade.',\n",
       "  0.5109771284273031],\n",
       " 'Aeromexico airline chatbot': ['Aeromexico airline chatbot running on Facebook Messenger, March 2018',\n",
       "  0.5939616834385282],\n",
       " 'field of AI research is natural': ['One pertinent field of AI research is natural language processing.',\n",
       "  0.7303984456220012],\n",
       " 'which is specific conversational agent.': ['uses a markup language called AIML, which is specific to its function as a conversational agent, and has since been adopted by various other developers of, so called, Alicebots.',\n",
       "  0.386202024728525]}"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### TESTINGS ####\n",
    "#print(df)\n",
    "\n",
    "## avec utilisation de la fonction qui a database en arg:\n",
    "#TFIDF_vectorizer, TF_IDF = read_data_preproc_dataframe('chatbot_database.txt')\n",
    "\n",
    "test_queries = [\n",
    "    'Do you think chatbots are really intelligent?',\n",
    "    \"'%' of companies using chatbots\",\n",
    "    \"2017 chatbots\",\n",
    "    \"According to Forrester (2015)\",\n",
    "    \"Aeromexico airline chatbot\",\n",
    "    \"field of AI research is natural\",\n",
    "    \"which is specific conversational agent.\"\n",
    "]\n",
    "\n",
    "dict_query_simmax = {}\n",
    "\n",
    "for query in test_queries:\n",
    "    ##sim_max, closest = get_closest_sentence([query], df_TFIDF, TFIDF_vectorizer)\n",
    "    ## AJOUTER df.Text en arg \n",
    "    sim_max, closest = get_closest_sentence([query], TF_IDF, TFIDF_vectorizer, df.Text)\n",
    "    dict_query_simmax[query] = [closest, sim_max]\n",
    "\n",
    "dict_query_simmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define greetings words and greetings answers in two separate variables.\n",
    "\n",
    "Greetings words should be words or short sentences like \"Hello\", \"Hey\", \"Hi\", What's up?\" and so on.\n",
    "The greetings answers can be words or short sentences that you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the greetings words and answers in two variables\n",
    "# We can define the input and answers\n",
    "greetings_inputs = ['Hello', 'Hi', 'Good morning', 'Hey']\n",
    "greetings_answers = ['Hey there, I am Vivabot, how can I help you?', 'Hello, my name is Vivabot, nice to meet you.',\n",
    "                     'Vivabot at your service, sir.', 'Hi Master, I am Vivabot.']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a Greetings function, called `greetings(sentence, greetings_inputs, greetings_outputs)`. If the variable `sentence` is in `greetings_inputs`, the function returns randomly a sentence from `greetings_outputs`. Otherwise the function returns nothing.\n",
    "\n",
    "Take into account when the case does not match too: for example 'hello' or 'Hello' should both work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the function greetings\n",
    "#fonction du cours\n",
    "def greetings(sentence, greetings_inputs, greetings_outputs):\n",
    "    ##sentence = input('User input :\\n>> ')\n",
    "\n",
    "    # Then if a sentence is in that input, let's choose an answer\n",
    "    if sentence in greetings_inputs:\n",
    "        output = np.random.randint(4)\n",
    "        print(greetings_answers[output])\n",
    "    else:\n",
    "        print('It was a pleasure. Bye!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utiliser Text input - output!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a pleasure. Bye!\n"
     ]
    }
   ],
   "source": [
    "greeting = input('enter a greeting')\n",
    "greetings(greeting, greetings_inputs, greetings_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to put it all together: let's define a function `vivabot(greetings_inputs, greetings_outputs, tf_idf, vectorizer, database)` that does the following:\n",
    "<ol>\n",
    "<li> Print some generic presentation </li>\n",
    "<li> Ask for text input </li>\n",
    "<li> If the text input is in greetings: call the function `greetings` and print its output using `greetings_inputs` and `greetings_ouputs`</li>\n",
    "<li> If the text input is not in greetings, calls the function `get_closest_sentence` and prints the closest sentence using `tf_idf`, `vectorizer` and `database`</li>\n",
    "<li> Go back to step 2 unless the text input is \"Bye\" </li>\n",
    "</ol> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement the function vivabot\n",
    "## AJOUTER df.Text en arg\n",
    "def vivabot(greetings_inputs, greetings_outputs, tf_idf, vectorizer, split_response, df_text):\n",
    "    ## Step:\n",
    "    # 1 - Print some generic presentation\n",
    "    # 2 - Ask for text input\n",
    "    # 3 - if the text input is in greetings:\n",
    "    #   -> call the function 'greetings' and print its output using 'greetings_inputs' and 'greetings_ouputs'\n",
    "    # 4 - If the text input is not in greetings:\n",
    "    #   -> calls the function 'get_closest_sentence' and prints the closest sentence using 'tf_idf', 'vectorizer' and 'database'\n",
    "    # 5 - Go back to step 2 unless the text input is \"Bye\"\n",
    "\n",
    "    #### question: database en argument pour closest_sentence !!??\n",
    "    ## VERSION-1: avec la database chatbot_database, sans database dans la signature de get_closest_sentence\n",
    "    ## VERSION-2: mettre la lecture de la database et prétraitements sur le dataframe dans des fonctions appelées avant get_closest_sentence()\n",
    "\n",
    "    print(f'This bot enables you to find the closest reference about chatbox to your query')\n",
    "    dict_query_simmax = {}\n",
    "    text_input = \"\"\n",
    "    iterator = 0\n",
    "    max_iters = 5\n",
    "\n",
    "    print(f'tf_idf.shape: {tf_idf.shape}')\n",
    "\n",
    "    while text_input.lower() != \"bye\" and iterator <= max_iters:\n",
    "        text_input = input('User input :\\n>> ') ## traiter le cas empty string !!\n",
    "        if text_input.lower() == \"bye\":\n",
    "            break\n",
    "        elif text_input in greetings_inputs:\n",
    "            greetings(text_input, greetings_inputs, greetings_answers)\n",
    "        else:\n",
    "            sim_max, closest = get_closest_sentence([text_input], tf_idf, vectorizer, df_text)\n",
    "            # ne prendre que la 2nde partie de closest sur '?' -- voir comment le faire sur '.' sans rien casser\n",
    "            #if split_response:\n",
    "            #    closest = closest.split('?')[1]\n",
    "            dict_query_simmax[text_input] = [closest, sim_max]\n",
    "        iterator += 1\n",
    "\n",
    "    return dict_query_simmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, call the function `vivabot` and see your chatbot coming to life!\n",
    "\n",
    "If it does not work well, call the functions one by one and check they all work properly independently first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST CHATBOT SUR chatbot_database.txt ou sur dialogs.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chatbot_database.txt'"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Pb avec dialogs.txt: -> Solution: PASSER df.Text en arg !! -> OK now\n",
    "databases = ['chatbot_database.txt', 'dialogs.txt']\n",
    "\n",
    "idx = 0\n",
    "database = databases[idx]\n",
    "database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Text  \\\n",
      "0   A chatbot (also known as a talkbot, chatterbot...   \n",
      "1   Such programs are often designed to convincing...   \n",
      "2   Chatbots are typically used in dialog systems ...   \n",
      "3   Some chatterbots use sophisticated natural lan...   \n",
      "4   The term \"ChatterBot\" was originally coined by...   \n",
      "..                                                ...   \n",
      "81  These cloud platforms provide Natural Language...   \n",
      "82  There are many APIs available for building you...   \n",
      "83  Malicious chatbots are frequently used to fill...   \n",
      "84  They are commonly found on Yahoo! Messenger, W...   \n",
      "85  There has also been a published report of a ch...   \n",
      "\n",
      "                                         Text_preproc  \n",
      "0   [a, chatbot, (, also, known, as, a, talkbot, ,...  \n",
      "1   [such, program, are, often, design, to, convin...  \n",
      "2   [chatbot, are, typic, use, in, dialog, system,...  \n",
      "3   [some, chatterbot, use, sophist, natur, langua...  \n",
      "4   [the, term, ``, chatterbot, '', wa, origin, co...  \n",
      "..                                                ...  \n",
      "81  [these, cloud, platform, provid, natur, langua...  \n",
      "82  [there, are, mani, api, avail, for, build, you...  \n",
      "83  [malici, chatbot, are, frequent, use, to, fill...  \n",
      "84  [they, are, commonli, found, on, yahoo, !, mes...  \n",
      "85  [there, ha, also, been, a, publish, report, of...  \n",
      "\n",
      "[86 rows x 2 columns]\n",
      "df.shape: (86, 2)\n",
      "This bot enables you to find the closest reference about chatbox to your query\n",
      "tf_idf.shape: (86, 718)\n",
      "phrase la + proche de ** of companies using chatbots **:\n",
      " A 2017 study showed 4% of companies used chatbots.\n",
      "phrase la + proche de ** 2017 chatbots **:\n",
      " A 2017 study showed 4% of companies used chatbots.\n",
      "phrase la + proche de ** According to Forrester (2015 **:\n",
      " According to Forrester (2015), AI will replace 16 percent of American jobs by the end of the decade.\n",
      "phrase la + proche de ** Aeromexico airline chatbot **:\n",
      " Aeromexico airline chatbot running on Facebook Messenger, March 2018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'of companies using chatbots': ['A 2017 study showed 4% of companies used chatbots.',\n",
       "  0.3362248410272699],\n",
       " '2017 chatbots': ['A 2017 study showed 4% of companies used chatbots.',\n",
       "  0.5144475319394324],\n",
       " 'According to Forrester (2015': ['According to Forrester (2015), AI will replace 16 percent of American jobs by the end of the decade.',\n",
       "  0.5109771284273031],\n",
       " 'Aeromexico airline chatbot': ['Aeromexico airline chatbot running on Facebook Messenger, March 2018',\n",
       "  0.5939616834385282]}"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: use your chatbot!\n",
    "TFIDF_vectorizer = None\n",
    "TF_IDF = None\n",
    "split_response = idx==1\n",
    "TFIDF_vectorizer, TF_IDF, df_Text = read_data_preproc_dataframe(database)\n",
    "TF_IDF\n",
    "\n",
    "dict_query_simmax = vivabot(greetings_inputs, greetings_answers, TF_IDF, TFIDF_vectorizer, split_response, df_Text)\n",
    "dict_query_simmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T12:25:22.679809Z",
     "start_time": "2019-08-07T12:25:22.676102Z"
    }
   },
   "source": [
    "**\\[BONUS\\]**: Let's implement some sentiment analysis features on our brand new chatbot:\n",
    "\n",
    "\n",
    "If the chatbot does not understand the user query (meaning the similarity is under a pre-defined threshold) implement a small talk function. The small talk function will take as input the query and return a positive or negative message depending on the tone (polarity) of the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pas compris ce qui est demandé dans cette partie.\n",
    "### comment établir la polarity à partir de la query ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-07T12:45:39.672871Z",
     "start_time": "2019-08-07T12:45:39.670401Z"
    }
   },
   "outputs": [],
   "source": [
    "small_talks_good = [\"Thanks for getting in touch with me\", \"I am so sorry I do not understand your point\", \n",
    "                   \"I'll make sure to understand you after my next update\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_talks_bad = [\"I can not understand a word of what you are saying\", \"Please be more specific\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement the function vivabot\n",
    "SIMILARITY_THRESHS = [0.1, 0.25, 0.4]\n",
    "\n",
    "def small_talk(query, similarity):\n",
    "    small_talk = \"\"\n",
    "    for idx in range(0,len(SIMILARITY_THRESHS)):\n",
    "        if similarity <= SIMILARITY_THRESHS[idx]:\n",
    "            small_talk = small_talks_good[idx]\n",
    "            break\n",
    "\n",
    "    return small_talk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many improvements can be done now if you have time: improving preprocessing, change your database if you want to use it for another reason\n",
    "\n",
    "This is your bot!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
