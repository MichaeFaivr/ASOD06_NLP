{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge - Text-Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1534770733765-337d273901c1?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1016&q=80)\n",
    "\n",
    "Photo by [Franck V.](https://unsplash.com/photos/oIMXkEuiXpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more data we have, the better performance we can achieve! It's easy with numerical data (see the lessons on Customer Churn and Anomaly Detection), but with texts it's a bit more complicated. We will see how to use word embeddings to do that.\n",
    "\n",
    "First of all, let's go back to the spam classifier challenge of the 01-Processing-Text course. The aim is to improve your results of this exercice with text augmentation.\n",
    "\n",
    "Remember, a spam classifier is a Machine Learning model that classifies texts (email or SMS) into two categories: spam (1) or ham (0).\n",
    "\n",
    "To do that, we will reuse our knowledge: we will apply preprocessing and BOW or Tf-Idf on a dataset of texts.\n",
    "Then we will use the logistic regression to predict to which class belong a new email/SMS, based on the BOW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:45:15.810076Z",
     "start_time": "2020-08-05T09:45:15.804012Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Import NLTK and all the needed libraries\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset in *spam.csv* using pandas. Use the 'latin-1' encoding as loading option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:45:25.145755Z",
     "start_time": "2020-08-05T09:45:25.141702Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : load data\n",
    "df = pd.read_csv('../input/spam.csv',on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the dataset and check the balance of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:45:38.595853Z",
     "start_time": "2020-08-05T09:45:38.591228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4825\n",
       "spam     747\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : how many spams and how many hams ?\n",
    "df.head()\n",
    "df.Class.value_counts()\n",
    "## imbalanced dataset: 4825 hams, 747 spams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 747 spams for 4825 hams, the datasets is a quite **unbalanced**.\n",
    "\n",
    "Before dealing with this problem, perform a classification using logistic regression and a BOW or Tf-Idf and compute the F1-score on the minority class (spam) with a classification report. \n",
    "\n",
    "> ⚠️ Hint : lemmatize your texts and set a random state for your classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:41:45.061548Z",
     "start_time": "2020-08-05T09:41:45.054109Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4825\n",
       "1     747\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : preprocessing\n",
    "df['Class'] = df['Class'].replace({'ham': 0, 'spam': 1})\n",
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:46:00.590407Z",
     "start_time": "2020-08-05T09:46:00.587008Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : preprocessing\n",
    "def preprocessing(document):\n",
    "    # 1- tokenization\n",
    "    tokens = word_tokenize(document)\n",
    "    # 2- punctuation removal\n",
    "    tokens = [t.lower() for t in tokens if t.isalpha()]\n",
    "    # 3- remove stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    tokens = [t for t in tokens if not t in stop_words]\n",
    "    # 4- lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens_lem = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[free, entry, wkly, comp, win, fa, cup, final,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[nah, think, goes, usf, lives, around, though]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                            Message\n",
       "0      0  [go, jurong, point, crazy, available, bugis, n...\n",
       "1      0                     [ok, lar, joking, wif, u, oni]\n",
       "2      1  [free, entry, wkly, comp, win, fa, cup, final,...\n",
       "3      0      [u, dun, say, early, hor, u, c, already, say]\n",
       "4      0     [nah, think, goes, usf, lives, around, though]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Message\"] = df.Message.apply(preprocessing)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build X and y\n",
    "y = df['Class'].to_numpy()\n",
    "X = df['Message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:46:10.810190Z",
     "start_time": "2020-08-05T09:46:10.807243Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (3733,)\n",
      "X_test.shape: (1839,)\n",
      "y_train.shape: (3733,)\n",
      "y_test.shape: (1839,)\n"
     ]
    }
   ],
   "source": [
    "# TODO : split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42,stratify=y)\n",
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:46:29.242471Z",
     "start_time": "2020-08-05T09:46:29.237102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : BOW or TFIDF\n",
    "# TFIDF trained on train subset\n",
    "vectorizer = TfidfVectorizer(lowercase=False, analyzer=lambda x: x)\n",
    "tf_idf_train = vectorizer.fit_transform(X_train).toarray()\n",
    "tf_idf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST: transform only on Test\n",
    "tf_idf_test = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:46:18.942274Z",
     "start_time": "2020-08-05T09:46:18.938675Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=100)\n",
    "lr.fit(tf_idf_train, y_train)\n",
    "\n",
    "# prédictions sur Train et Test\n",
    "y_pred_train = lr.predict(tf_idf_train)\n",
    "y_pred_test  = lr.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:46:46.531741Z",
     "start_time": "2020-08-05T09:46:46.526876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F1-score sur Train - Ham: 0.9790718835304824\n",
      " F1-score sur Train - Spam: 0.841743119266055\n",
      " F1-score sur Test - Ham: 0.9736196319018404\n",
      " F1-score sur Test - Spam: 0.7942583732057416\n"
     ]
    }
   ],
   "source": [
    "# TODO : check the F1-score on the minority class\n",
    "from sklearn.metrics import f1_score,recall_score,precision_score\n",
    "# F1-score de Train sur ham et spam\n",
    "vect_f1_score_train = f1_score(y_train, y_pred_train, average=None)\n",
    "print(f\" F1-score sur Train - Ham: {vect_f1_score_train[0]}\")\n",
    "print(f\" F1-score sur Train - Spam: {vect_f1_score_train[1]}\")\n",
    "# F1-score de Test\n",
    "vect_f1_score_test = f1_score(y_test, y_pred_test, average=None)\n",
    "print(f\" F1-score sur Test - Ham: {vect_f1_score_test[0]}\")\n",
    "print(f\" F1-score sur Test - Spam: {vect_f1_score_test[1]}\")\n",
    "## F1-score sur Test - Spam: 0.7942583732057416\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are good, but can we do better ? We can try to **make the dataset less unbalanced**. We need to create new spams ! The naive approach would be to duplicate the spams, but this may not work very well and may simply generate overfitting. \n",
    "\n",
    "Instead, **we will use the word embeddings to find synonyms**. With synonyms we can generate new spams without duplicating the texts, so it's a little smarter.\n",
    "\n",
    "How can we find synonyms with words embeddings ? If you have two words whose embeddings have a very high cosine similarity, you can assume they're synonymous. \n",
    "\n",
    "In the course we saw how to use the pre-trained Glove model containing 400000 words and their vector representation. The problem with this model is that if we have to find the closest word in the whole model we have to calculate 399999 consine similarity, which would take far too much time!\n",
    "\n",
    "For this we will use another Glove model which allows us to do this much faster. \n",
    "\n",
    "First of all download the model from the Glove API. The following snippet of code does just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:40:56.650235Z",
     "start_time": "2020-08-05T09:39:31.982899Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load(\"glove-wiki-gigaword-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7fd3ee4903d0>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `model.word_vec()` we can display the vector representation of a word. Try with some words, how many dimensions does each vector have in this model ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:47:44.378058Z",
     "start_time": "2020-08-05T09:47:44.373610Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_507715/904921815.py:3: DeprecationWarning: Call to deprecated `word_vec` (Use get_vector instead).\n",
      "  word_embedding = model.word_vec('present')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.19623 ,  0.26213 ,  0.46284 ,  0.23267 , -0.21188 ,  0.051022,\n",
       "       -0.28305 ,  0.39192 ,  0.13012 ,  0.071752, -0.18406 ,  0.084196,\n",
       "        0.34822 ,  0.18919 ,  0.62453 , -0.55918 ,  0.19213 , -0.017218,\n",
       "       -0.55026 , -0.02437 , -0.34945 , -0.40632 ,  0.33808 , -0.043692,\n",
       "       -0.3734  , -0.85703 ,  0.54926 ,  0.009388,  0.49106 , -0.17067 ,\n",
       "        0.16493 ,  0.32655 ,  0.072014, -0.19438 ,  0.10654 ,  0.46349 ,\n",
       "        0.61987 , -0.13063 , -0.20617 , -0.12397 , -0.47928 , -0.04128 ,\n",
       "        0.34817 , -0.14162 ,  0.38493 ,  0.11754 ,  0.037054, -0.36628 ,\n",
       "       -0.58683 , -0.64051 ,  0.42736 , -0.30208 ,  0.70955 ,  0.7739  ,\n",
       "       -0.020319, -2.2776  , -0.39541 , -0.62158 ,  1.0597  ,  0.18122 ,\n",
       "       -0.34483 ,  0.90861 , -0.15188 ,  0.0294  ,  0.79108 , -0.21084 ,\n",
       "        0.1694  , -0.043356,  0.21957 , -0.36199 ,  0.30797 , -0.061459,\n",
       "       -0.039168, -0.442   ,  0.40566 , -0.155   , -0.35937 , -0.28062 ,\n",
       "       -0.79322 , -0.40449 , -0.23335 ,  0.33136 , -0.10282 ,  0.26363 ,\n",
       "       -1.0878  ,  0.2564  ,  0.16239 , -0.25618 ,  0.55617 , -0.1659  ,\n",
       "        0.20507 , -0.60343 , -0.16343 , -0.18401 , -0.3469  , -0.1287  ,\n",
       "       -0.50018 , -0.73606 ,  0.83573 , -0.15658 ], dtype=float32)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : how many dimensions in the embedding ?\n",
    "# Then you can get the embedding of a word as a numpy array this way\n",
    "word_embedding = model.word_vec('present')\n",
    "word_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `model.most_similar('word', topn = 5)` we can find the 5 words that are the most similar (in terms of cosine similarity) to our given word. Try with with *house* and with *fox*. Is it always relevant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:47:56.619149Z",
     "start_time": "2020-08-05T09:47:56.615608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('office', 0.7581615447998047),\n",
       " ('senate', 0.7204986810684204),\n",
       " ('room', 0.7149738669395447),\n",
       " ('houses', 0.6888046264648438),\n",
       " ('capitol', 0.6851760149002075)]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : 5 most similar words to \"house\"\n",
    "model.most_similar('house', topn = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:48:12.196056Z",
     "start_time": "2020-08-05T09:48:12.192186Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abc', 0.7963388562202454),\n",
       " ('nbc', 0.7775211334228516),\n",
       " ('cbs', 0.7563193440437317),\n",
       " ('television', 0.7360690236091614),\n",
       " ('tv', 0.708899736404419)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : 5 most similar words to \"fox\"\n",
    "model.most_similar('fox', topn = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will generate the new spams. To simplify the task, we will replace only the names. Names can be identified by their POS-tag 'NN' with `nltk.pos_tag`.\n",
    "\n",
    "This is the way to do it:\n",
    "- isolate the tokenized spams in a variable\n",
    "- add the POS-tag to all spam tokens\n",
    "- replace each token with the top 1 most similar word if 2 conditions are met: the POS-tag == 'NN' and the token has an embedding. \n",
    "\n",
    "> ⚠️ Hint : to verify that a word has a vector representation we can use `model.vocab`. \n",
    "<br>Example :\n",
    "\n",
    "```python\n",
    "\"house\" in model.vocab\n",
    ">> True\n",
    "```\n",
    "\n",
    "- finaly, add new spams to the dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Leakage si on le fait avant le split train-test\n",
    "### il faut en fait ajouter les new_spams au X_train uniquement: voir ce qui est fait dans EXO-2 Quora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:48:32.533436Z",
     "start_time": "2020-08-05T09:48:32.530536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       [free, entry, wkly, comp, win, fa, cup, final,...\n",
       "5       [freemsg, hey, darling, week, word, back, like...\n",
       "8       [winner, valued, network, customer, selected, ...\n",
       "9       [mobile, months, u, r, entitled, update, lates...\n",
       "11      [six, chances, win, cash, pounds, txt, send, c...\n",
       "                              ...                        \n",
       "5537    [want, explicit, sex, secs, ring, costs, gsex,...\n",
       "5540    [asked, chatlines, inclu, free, mins, india, c...\n",
       "5547    [contract, mobile, mnths, latest, motorola, no...\n",
       "5566    [reminder, get, pounds, free, call, credit, de...\n",
       "5567    [time, tried, contact, u, pound, prize, claim,...\n",
       "Name: Message, Length: 747, dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : isolate the tokenized spams in a variable\n",
    "tokenized_spams = df[df['Class']==1].Message\n",
    "tokenized_spams \n",
    "##df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:48:34.965666Z",
     "start_time": "2020-08-05T09:48:34.960885Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       [(free, JJ), (entry, NN), (wkly, VBD), (comp, ...\n",
       "5       [(freemsg, NN), (hey, NN), (darling, VBG), (we...\n",
       "8       [(winner, NN), (valued, VBN), (network, NN), (...\n",
       "9       [(mobile, JJ), (months, NNS), (u, JJ), (r, NN)...\n",
       "11      [(six, CD), (chances, NNS), (win, VBP), (cash,...\n",
       "                              ...                        \n",
       "5537    [(want, NN), (explicit, NN), (sex, NN), (secs,...\n",
       "5540    [(asked, VBN), (chatlines, NNS), (inclu, RB), ...\n",
       "5547    [(contract, NN), (mobile, JJ), (mnths, NNS), (...\n",
       "5566    [(reminder, NN), (get, VB), (pounds, NNS), (fr...\n",
       "5567    [(time, NN), (tried, VBN), (contact, NN), (u, ...\n",
       "Name: Message, Length: 747, dtype: object"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : add the POS-tag to all spam tokens\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "# list if list of tagged tokend\n",
    "#pos_tag_spams = [pos_tag(spam) for spam in tokenized_spams]\n",
    "#pos_tag_spams\n",
    "\n",
    "pos_tag_spams = tokenized_spams.apply(nltk.pos_tag)\n",
    "pos_tag_spams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.19623 ,  0.26213 ,  0.46284 ,  0.23267 , -0.21188 ,  0.051022,\n",
       "       -0.28305 ,  0.39192 ,  0.13012 ,  0.071752, -0.18406 ,  0.084196,\n",
       "        0.34822 ,  0.18919 ,  0.62453 , -0.55918 ,  0.19213 , -0.017218,\n",
       "       -0.55026 , -0.02437 , -0.34945 , -0.40632 ,  0.33808 , -0.043692,\n",
       "       -0.3734  , -0.85703 ,  0.54926 ,  0.009388,  0.49106 , -0.17067 ,\n",
       "        0.16493 ,  0.32655 ,  0.072014, -0.19438 ,  0.10654 ,  0.46349 ,\n",
       "        0.61987 , -0.13063 , -0.20617 , -0.12397 , -0.47928 , -0.04128 ,\n",
       "        0.34817 , -0.14162 ,  0.38493 ,  0.11754 ,  0.037054, -0.36628 ,\n",
       "       -0.58683 , -0.64051 ,  0.42736 , -0.30208 ,  0.70955 ,  0.7739  ,\n",
       "       -0.020319, -2.2776  , -0.39541 , -0.62158 ,  1.0597  ,  0.18122 ,\n",
       "       -0.34483 ,  0.90861 , -0.15188 ,  0.0294  ,  0.79108 , -0.21084 ,\n",
       "        0.1694  , -0.043356,  0.21957 , -0.36199 ,  0.30797 , -0.061459,\n",
       "       -0.039168, -0.442   ,  0.40566 , -0.155   , -0.35937 , -0.28062 ,\n",
       "       -0.79322 , -0.40449 , -0.23335 ,  0.33136 , -0.10282 ,  0.26363 ,\n",
       "       -1.0878  ,  0.2564  ,  0.16239 , -0.25618 ,  0.55617 , -0.1659  ,\n",
       "        0.20507 , -0.60343 , -0.16343 , -0.18401 , -0.3469  , -0.1287  ,\n",
       "       -0.50018 , -0.73606 ,  0.83573 , -0.15658 ], dtype=float32)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_embedding = model.get_vector('present')\n",
    "word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:48:47.665203Z",
     "start_time": "2020-08-05T09:48:47.662267Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsynonymes_tokens = [\\n    [t_pos[0] if t_pos[1] != 'NN' else (model.most_similar(t_pos[0], topn = 1)[0][0], 'NN')\\n     for t_pos in tokenized_spams_elt] for tokenized_spams_elt in tokenized_spams\\n]\\nsynonymes_tokens\\n\""
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : replace token with the top 1 most similar word if 2 conditions are met:\n",
    "# the POS-tag == 'NN' and the token has an embedding.\n",
    "## Pb avec l'error: AttributeError: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\n",
    "vocab = model.key_to_index\n",
    "vocab\n",
    "def replace_to_synonyme(tagged_tokens):\n",
    "    ## issue with model.vocab\n",
    "    tokens = [t_pos[0] if t_pos[1]!='NN' or t_pos[0] not in vocab\n",
    "              else model.most_similar(t_pos[0], topn = 1)[0][0] for t_pos in tagged_tokens]\n",
    "    return tokens\n",
    "\n",
    "synonymes_tokens = pos_tag_spams.apply(replace_to_synonyme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       [free, enter, wkly, att, victory, fa, cup, fin...\n",
       "5       [freemsg, yeah, darling, month, phrase, back, ...\n",
       "8       [winners, valued, networks, customers, selecte...\n",
       "9       [mobile, months, u, d, entitled, update, lates...\n",
       "11      [six, chances, win, money, pounds, txt, send, ...\n",
       "                              ...                        \n",
       "5537    [do, implicit, sexual, 1min, rings, costs, gse...\n",
       "5540    [asked, chatlines, inclu, free, mins, india, h...\n",
       "5547    [contracts, mobile, mnths, latest, nokia, eric...\n",
       "5566    [reminders, get, pounds, free, calls, loans, d...\n",
       "5567    [when, tried, contacts, u, pounds, nobel, clai...\n",
       "Name: Message, Length: 747, dtype: object"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonymes_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:48:55.359312Z",
     "start_time": "2020-08-05T09:48:55.356076Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fancy',\n",
       " 'shag',\n",
       " 'txt',\n",
       " 'xxuk',\n",
       " 'suzy',\n",
       " 'txts',\n",
       " 'cost',\n",
       " 'per',\n",
       " 'msg',\n",
       " 'tncs',\n",
       " 'website',\n",
       " 'x']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : compare a spam with this new version\n",
    "print(tokenized_spams.iloc[50])\n",
    "print(synonymes_tokens.iloc[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fancy',\n",
       " 'carpeting',\n",
       " 'obj',\n",
       " 'xxuk',\n",
       " 'veronica',\n",
       " 'txts',\n",
       " 'costs',\n",
       " 'per',\n",
       " 'msg',\n",
       " 'shgs',\n",
       " 'web',\n",
       " 'g']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AJOUTER les ROWS associées à synonymes_tokens et 0/1 dans y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:49:10.300769Z",
     "start_time": "2020-08-05T09:49:10.297302Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_507715/598713160.py:2: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_more = X.append(pd.Series(synonymes_tokens), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       [go, jurong, point, crazy, available, bugis, n...\n",
       "1                          [ok, lar, joking, wif, u, oni]\n",
       "2       [free, entry, wkly, comp, win, fa, cup, final,...\n",
       "3           [u, dun, say, early, hor, u, c, already, say]\n",
       "4          [nah, think, goes, usf, lives, around, though]\n",
       "                              ...                        \n",
       "6314    [do, implicit, sexual, 1min, rings, costs, gse...\n",
       "6315    [asked, chatlines, inclu, free, mins, india, h...\n",
       "6316    [contracts, mobile, mnths, latest, nokia, eric...\n",
       "6317    [reminders, get, pounds, free, calls, loans, d...\n",
       "6318    [when, tried, contacts, u, pounds, nobel, clai...\n",
       "Name: Message, Length: 6319, dtype: object"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : add the newly generated spams to the dataset\n",
    "X_more = X.append(pd.Series(synonymes_tokens), ignore_index=True)\n",
    "X_more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:49:29.935311Z",
     "start_time": "2020-08-05T09:49:29.931626Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_507715/2145387452.py:4: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_more = y_more.append(pd.Series(np.ones(len(synonymes_tokens))), ignore_index=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0.0\n",
       "1       0.0\n",
       "2       1.0\n",
       "3       0.0\n",
       "4       0.0\n",
       "       ... \n",
       "6314    1.0\n",
       "6315    1.0\n",
       "6316    1.0\n",
       "6317    1.0\n",
       "6318    1.0\n",
       "Length: 6319, dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO : add new labels to your `y` variable\n",
    "## all class==1 as they are new spams\n",
    "y_more = pd.Series(y)\n",
    "y_more = y_more.append(pd.Series(np.ones(len(synonymes_tokens))), ignore_index=True)\n",
    "y_more\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (4233,)\n",
      "X_test.shape: (2086,)\n",
      "y_train.shape: (4233,)\n",
      "y_test.shape: (2086,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_more, y_more, test_size=0.33, random_state=42,stratify=y_more)\n",
    "print(f'X_train.shape: {X_train.shape}')\n",
    "print(f'X_test.shape: {X_test.shape}')\n",
    "print(f'y_train.shape: {y_train.shape}')\n",
    "print(f'y_test.shape: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:49:45.939858Z",
     "start_time": "2020-08-05T09:49:45.936046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4825\n",
      "1494\n"
     ]
    }
   ],
   "source": [
    "# TODO : check the balance of your dataset. It should be a little less imablanced.\n",
    "### pourquoi le ds serait moins imbalanced ? à voir\n",
    "print(len(y_more[y_more==0]))\n",
    "print(len(y_more[y_more==1]))\n",
    "# OK better balanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1319                               [correct, work, today]\n",
       "1983    [wnt, buy, bmw, car, urgently, vry, hv, shorta...\n",
       "3840                         [howz, come, said, medicine]\n",
       "5460    [december, mobile, entitled, update, latest, c...\n",
       "2318                                    [way, office, da]\n",
       "                              ...                        \n",
       "3196    [poking, man, everyday, teach, canada, abi, sa...\n",
       "1967       [even, cant, close, eyes, vava, playing, umma]\n",
       "5326                                       [makes, happy]\n",
       "2582    [free, tarot, texts, find, love, life, try, fr...\n",
       "5584    [valued, customers, pleased, advising, followi...\n",
       "Name: Message, Length: 4233, dtype: object"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1319    0.0\n",
       "1983    0.0\n",
       "3840    0.0\n",
       "5460    1.0\n",
       "2318    0.0\n",
       "       ... \n",
       "3196    0.0\n",
       "1967    0.0\n",
       "5326    0.0\n",
       "2582    1.0\n",
       "5584    1.0\n",
       "Length: 4233, dtype: float64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4233, 6278)\n",
      "(4233,)\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF again\n",
    "# TFIDF trained on train subset\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x)\n",
    "tf_idf_train = vectorizer.fit_transform(X_train).toarray()\n",
    "tf_idf_test = vectorizer.transform(X_test).toarray()\n",
    "\n",
    "print(tf_idf_train.shape)\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:49:54.023119Z",
     "start_time": "2020-08-05T09:49:54.019718Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO : Split your data with the same random state as before (fait ci-dessus) and\n",
    "# do a new prediction with the logistic regression and the same random state as before\n",
    "lr = LogisticRegression(max_iter=100)\n",
    "lr.fit(tf_idf_train, y_train)\n",
    "\n",
    "# prédictions sur Train et Test\n",
    "y_pred_train = lr.predict(tf_idf_train)\n",
    "y_pred_test  = lr.predict(tf_idf_test)\n",
    "\n",
    "## F1-score test sur spams: 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-05T09:50:02.398195Z",
     "start_time": "2020-08-05T09:50:02.394721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " F1-score sur Train - Ham: 0.9799270072992701\n",
      " F1-score sur Train - Spam: 0.9301587301587302\n",
      " F1-score sur Test - Ham: 0.969122592479364\n",
      " F1-score sur Test - Spam: 0.8879023307436182\n"
     ]
    }
   ],
   "source": [
    "# TODO : Evaluate the new prediction on the minority class, is it better ?\n",
    "# F1-score de Train sur ham et spam\n",
    "vect_f1_score_train = f1_score(y_train, y_pred_train, average=None)\n",
    "print(f\" F1-score sur Train - Ham: {vect_f1_score_train[0]}\")\n",
    "print(f\" F1-score sur Train - Spam: {vect_f1_score_train[1]}\")\n",
    "# F1-score de Test\n",
    "vect_f1_score_test = f1_score(y_test, y_pred_test, average=None)\n",
    "print(f\" F1-score sur Test - Ham: {vect_f1_score_test[0]}\")\n",
    "print(f\" F1-score sur Test - Spam: {vect_f1_score_test[1]}\")\n",
    "## F1-score sur Test - Spam: 0.7942583732057416"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
