{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the dataset \n",
    "df = pd.read_csv('trump_tweet_2016.csv',sep='|',on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                    source                                               text  \\\n",
       "0      Twitter for iPhone  RT @realDonaldTrump: Happy Birthday @DonaldJTr...   \n",
       "1      Twitter for iPhone  Happy Birthday @DonaldJTrumpJr!https://t.co/uR...   \n",
       "2     Twitter for Android  Happy New Year to all, including to my many en...   \n",
       "3     Twitter for Android  Russians are playing @CNN and @NBCNews for suc...   \n",
       "4      Twitter for iPhone  Join @AmerIcan32, founded by Hall of Fame lege...   \n",
       "...                   ...                                                ...   \n",
       "3913   Twitter for iPhone      #HappyNewYearAmerica! https://t.co/EeQb8PDrUe   \n",
       "3914   Twitter for iPhone  HAPPY NEW YEAR &amp; THANK YOU! https://t.co/Y...   \n",
       "3915  Twitter for Android  I will be on @FoxNews live,  with members of m...   \n",
       "3916  Twitter for Android  I would like to wish everyone A HAPPY AND HEAL...   \n",
       "3917  Twitter for Android  Do you believe that The State Department, on N...   \n",
       "\n",
       "               created_at  retweet_count  favorite_count  is_retweet  \\\n",
       "0     12-31-2016 18:59:04           9529               0        True   \n",
       "1     12-31-2016 18:58:12           9529           55601       False   \n",
       "2     12-31-2016 13:17:21         141853          350860       False   \n",
       "3     12-30-2016 22:18:18          23213           84254       False   \n",
       "4     12-30-2016 19:46:55           7366           25336       False   \n",
       "...                   ...            ...             ...         ...   \n",
       "3913  01-01-2016 05:18:23           3434            9143       False   \n",
       "3914  01-01-2016 03:25:27           3460            8581       False   \n",
       "3915  01-01-2016 00:44:14           2108            6735       False   \n",
       "3916  12-31-2015 23:21:49           6776           16495       False   \n",
       "3917  12-31-2015 23:11:35           2755            6824       False   \n",
       "\n",
       "                  id_str  \n",
       "0     815271067749060609  \n",
       "1     815270850916208644  \n",
       "2     815185071317676033  \n",
       "3     814958820980039681  \n",
       "4     814920722208296960  \n",
       "...                  ...  \n",
       "3913  682792967736848385  \n",
       "3914  682764544402440192  \n",
       "3915  682723973449289728  \n",
       "3916  682703233492619264  \n",
       "3917  682700657304989697  \n",
       "\n",
       "[3918 rows x 7 columns]>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source', 'text', 'created_at', 'retweet_count', 'favorite_count',\n",
       "       'is_retweet', 'id_str'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## target: source\n",
    "df['source'].unique()\n",
    "## hypothèse: Android -> Trump; autres -> team\n",
    "df['target'] = df['source'].apply(lambda x: int('Android' in x))\n",
    "df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2228\n",
       "1    1690\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(document):\n",
    "    # 1- tokenization\n",
    "    tokens = word_tokenize(document)\n",
    "    # 2- punctuation removal\n",
    "    tokens = [t.lower() for t in tokens if t.isalpha()]\n",
    "    # 3- remove stopwords\n",
    "    stop_words = stopwords.words('english')\n",
    "    tokens = [t for t in tokens if not t in stop_words]\n",
    "    # 4- lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens_lem = [lemmatizer.lemmatize(t) for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "## voir comment faire pour éviter le data leakage aussi dans les pré-processing NLP:\n",
    "## faire le split train / test avant ?\n",
    "## split data\n",
    "y = df['target'].to_numpy()\n",
    "X = df.drop(columns=['source','target'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = 42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 6)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## faire le preproc NLP sur train et test séparément\n",
    "features = [col for col in df.columns if col not in ['source','target']]\n",
    "features\n",
    "df_train = pd.DataFrame(X_train)\n",
    "df_train.columns = features\n",
    "\n",
    "df_test = pd.DataFrame(X_test)\n",
    "df_test.columns = features\n",
    "\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>id_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>@red77angelluis: @realDonaldTrump @NeilTurner_...</td>\n",
       "      <td>01-25-2016 04:07:08</td>\n",
       "      <td>752</td>\n",
       "      <td>2823</td>\n",
       "      <td>False</td>\n",
       "      <td>691472343449870336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>Instead of driving jobs and wealth away, AMERI...</td>\n",
       "      <td>09-27-2016 01:28:04</td>\n",
       "      <td>7648</td>\n",
       "      <td>20743</td>\n",
       "      <td>False</td>\n",
       "      <td>780579728964980736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3621</th>\n",
       "      <td>Failing @GlennBeck lost all credibility. Not o...</td>\n",
       "      <td>01-23-2016 16:54:37</td>\n",
       "      <td>2028</td>\n",
       "      <td>4565</td>\n",
       "      <td>False</td>\n",
       "      <td>690940712578195457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>More poll results from last nights Commander-i...</td>\n",
       "      <td>09-08-2016 23:56:22</td>\n",
       "      <td>10284</td>\n",
       "      <td>25291</td>\n",
       "      <td>False</td>\n",
       "      <td>774033670239760384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>Have a great Memorial Day and remember that we...</td>\n",
       "      <td>05-30-2016 11:26:47</td>\n",
       "      <td>9159</td>\n",
       "      <td>25545</td>\n",
       "      <td>False</td>\n",
       "      <td>737243856144629760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text           created_at  \\\n",
       "3594  @red77angelluis: @realDonaldTrump @NeilTurner_...  01-25-2016 04:07:08   \n",
       "895   Instead of driving jobs and wealth away, AMERI...  09-27-2016 01:28:04   \n",
       "3621  Failing @GlennBeck lost all credibility. Not o...  01-23-2016 16:54:37   \n",
       "1030  More poll results from last nights Commander-i...  09-08-2016 23:56:22   \n",
       "2028  Have a great Memorial Day and remember that we...  05-30-2016 11:26:47   \n",
       "\n",
       "      retweet_count  favorite_count  is_retweet              id_str  \n",
       "3594            752            2823       False  691472343449870336  \n",
       "895            7648           20743       False  780579728964980736  \n",
       "3621           2028            4565       False  690940712578195457  \n",
       "1030          10284           25291       False  774033670239760384  \n",
       "2028           9159           25545       False  737243856144629760  "
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRES IMPORTANT !! VECTORIZATION: fitter le vectorizer uniquement sur le train (pour ne pas avoir de Data Leakage!)\n",
    "### puis l'appliquer séparément à Train et Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvectorizer = CountVectorizer(analyzer=lambda x: x)\\nvectorizer.fit(X_train)\\n\\nBOW_train = vectorizer.fit_transform([preprocessing(x) for x in df_train.text]).toarray()\\ncolonnes = vectorizer.get_feature_names_out()\\n\\ndf_bow_train = pd.DataFrame(data=BOW_train, columns=colonnes)  ## être sûr du phasage entre les valeurs et les colonnes\\ndf_bow_train\\n'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Vectorization de TRAIN: voir 3 blocs + bas\n",
    "\"\"\"\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "BOW_train = vectorizer.fit_transform([preprocessing(x) for x in df_train.text]).toarray()\n",
    "colonnes = vectorizer.get_feature_names_out()\n",
    "\n",
    "df_bow_train = pd.DataFrame(data=BOW_train, columns=colonnes)  ## être sûr du phasage entre les valeurs et les colonnes\n",
    "df_bow_train\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nvectorizer = CountVectorizer(analyzer=lambda x: x)\\nBOW_test = vectorizer.fit_transform([preprocessing(x) for x in df_test.text]).toarray()\\ncolonnes = vectorizer.get_feature_names_out()\\n\\ndf_bow_test = pd.DataFrame(data=BOW_test, columns=colonnes)  ## être sûr du phasage entre les valeurs et les colonnes\\ndf_bow_test #784x2515\\n'"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## pas de vectorization de test sur la base de test\n",
    "## vectorization de test sur la base de la vectorization fittée sur train\n",
    "\"\"\"\n",
    "vectorizer = CountVectorizer(analyzer=lambda x: x)\n",
    "BOW_test = vectorizer.fit_transform([preprocessing(x) for x in df_test.text]).toarray()\n",
    "colonnes = vectorizer.get_feature_names_out()\n",
    "\n",
    "df_bow_test = pd.DataFrame(data=BOW_test, columns=colonnes)  ## être sûr du phasage entre les valeurs et les colonnes\n",
    "df_bow_test #784x2515\n",
    "\"\"\"\n",
    "### !!! PB de DIMENSIONS: Nb features >> Nb Rows !!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! PB de DIMENSIONS: Nb features >> Nb Rows !!!!! voir comment faire dans ce cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW in spam case: https              1575\n",
      "thank               488\n",
      "great               471\n",
      "hillary             397\n",
      "trump               348\n",
      "amp                 319\n",
      "realdonaldtrump     318\n",
      "twitter             280\n",
      "clinton             240\n",
      "america             228\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## sans distinction sur la target\n",
    "print(f\"BOW in spam case: {df_bow_train.sum(axis=0).sort_values(ascending=False)[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "## essai avec les lignes issues du code de V.Malara\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0,stratify=y)\n",
    "# instanciation du vectorizer\n",
    "#comprendre pourquoi on utilise dans certains cas : lambda x:x et d'autres la version ci-dessous\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# entraînement du vectorizer sur la base de train uniquement\n",
    "vectorizer.fit(X_train) ## vectorizer entrainé sur la base de train uniquement pour ne pas avoir de data leakage\n",
    "\n",
    "# application du vectorizer sur train et test pour la création des BOW sur train et test\n",
    "X_bow_train = pd.DataFrame(vectorizer.transform(X_train).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "X_bow_test  = pd.DataFrame(vectorizer.transform(X_test).toarray(), columns=vectorizer.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform a logistic regression to predict whether a message is a spam or not\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,recall_score,precision_score\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_model(model, X_train, X_test, y_train, y_test):\n",
    "    metrics = {}\n",
    "\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred  = model.predict(X_test)\n",
    "\n",
    "    ## F1-score\n",
    "    metrics['f1score_train'] = f1score_train = f1_score(y_train, y_train_pred)\n",
    "    metrics['f1score_test']  = f1score_test  = f1_score(y_test, y_test_pred)\n",
    "\n",
    "    ## PRECISION\n",
    "    metrics['precision_train'] = precision_train = precision_score(y_train,y_train_pred)\n",
    "    metrics['precision_test']  = precision_test  = precision_score(y_test,y_test_pred)\n",
    "\n",
    "    ## RECALL\n",
    "    metrics['recall_train'] = recall_train = recall_score(y_train,y_train_pred)\n",
    "    metrics['recall_test']  = recall_test  = recall_score(y_test,y_test_pred)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bow_train = df_bow_train\n",
    "X_bow_test = df_bow_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   abandon  abc  abcpolitics  able  abolish  absentee  absolutely  abused  \\\n",
      "0        0    0            0     0        0         0           0       0   \n",
      "1        0    0            0     0        0         0           0       0   \n",
      "2        0    0            0     0        0         0           0       0   \n",
      "3        0    0            0     0        0         0           0       0   \n",
      "4        0    0            0     0        0         0           0       0   \n",
      "\n",
      "   abuser  accept  ...  yes  yesterday  yet  york  yorkers  youngstown  youth  \\\n",
      "0       0       0  ...    0          0    0     0        0           0      0   \n",
      "1       0       0  ...    0          0    0     0        0           0      0   \n",
      "2       0       0  ...    0          0    1     0        0           0      0   \n",
      "3       0       0  ...    0          0    0     0        0           0      0   \n",
      "4       0       0  ...    0          0    0     0        0           0      0   \n",
      "\n",
      "   youtube  zero  zuckerman  \n",
      "0        0     0          0  \n",
      "1        0     0          0  \n",
      "2        0     0          0  \n",
      "3        0     0          0  \n",
      "4        0     0          0  \n",
      "\n",
      "[5 rows x 2515 columns]\n",
      "(784, 2515)\n",
      "(3134, 5516)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- abused\n- abuser\n- achieve\n- add\n- address\n- ...\nFeature names seen at fit time, yet now missing:\n- abandoned\n- abdeslam\n- abedin\n- aberdeen\n- ability\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [265], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#y_train_pred = grid.predict(X_bow_train)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#y_test_pred = grid.predict(X_bow_test)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m lr\u001b[38;5;241m.\u001b[39mfit(X_bow_train, y_train)\n\u001b[0;32m---> 15\u001b[0m y_test_pred \u001b[38;5;241m=\u001b[39m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_bow_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m dict_scores_models \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/artefact/lib/python3.10/site-packages/sklearn/linear_model/_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    453\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/artefact/lib/python3.10/site-packages/sklearn/linear_model/_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    429\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[1;32m    434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/artefact/lib/python3.10/site-packages/sklearn/base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    511\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    517\u001b[0m ):\n\u001b[1;32m    518\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    586\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/envs/artefact/lib/python3.10/site-packages/sklearn/base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    503\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m     )\n\u001b[0;32m--> 507\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- abused\n- abuser\n- achieve\n- add\n- address\n- ...\nFeature names seen at fit time, yet now missing:\n- abandoned\n- abdeslam\n- abedin\n- aberdeen\n- ability\n- ...\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'C': [0.2,0.5],\n",
    "     }\n",
    "\n",
    "lr = LogisticRegression()\n",
    "##grid = RandomizedSearchCV(lr, param_dist, cv=3, n_iter=30, scoring = 'f1')\n",
    "##grid.fit(X_bow_train, y_train)\n",
    "##print(f'grid.best_params_: {grid.best_params_}')\n",
    "print(X_bow_test.head())\n",
    "print(X_bow_test.shape)\n",
    "print(X_bow_train.shape)\n",
    "#y_train_pred = grid.predict(X_bow_train)\n",
    "#y_test_pred = grid.predict(X_bow_test)\n",
    "lr.fit(X_bow_train, y_train)\n",
    "y_test_pred = lr.predict(X_bow_test)\n",
    "''\n",
    "\n",
    "dict_scores_models = {}\n",
    "#dict_scores_lr = scores_model(grid, X_bow_train, X_bow_test, y_train, y_test)\n",
    "dict_scores_lr = scores_model(lr, X_bow_train, X_bow_test, y_train, y_test)\n",
    "dict_scores_models['LogisticRegression'] = dict_scores_lr\n",
    "dict_scores_models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artefact",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
