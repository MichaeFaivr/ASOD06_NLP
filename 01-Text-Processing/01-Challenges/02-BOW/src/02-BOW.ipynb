{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02-BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1543549477-d62fd00770d9?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1189&q=80)\n",
    "\n",
    "Photo by [Sheldon Nunes](https://unsplash.com/photos/IfHj-ucav3c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we master the preprocessing, let's make our first Bag Of Words (BOW)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reuse our dataset of Coldplay songs to make a BOW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, the first step is to import some libraries. So import *nltk* as well as all the libraries you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import NLTK and all the needed libraries\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load now the dataset in *coldplay.csv* using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the dataset in coldplay.csv\n",
    "df = pd.read_csv('coldplay.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You already know this dataset, but you can check it again if you want to refresh your memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Artist  120 non-null    object\n",
      " 1   Song    120 non-null    object\n",
      " 2   Link    120 non-null    object\n",
      " 3   Lyrics  120 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 3.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# TODO: Explore the data\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the *CountVectorizer* of scikit-learn, make a BOW of all the lyrics of Coldplay, and print the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute a BOW of all the lyrics in the csv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=1000, stop_words='english')\n",
    "BOW = vectorizer.fit_transform(df.Lyrics).toarray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the BOW matrix, we would like to have a new dataframe having the BOW for each song, and as columns the corresponding words (just as we did in the lecture at the end).\n",
    "\n",
    "So that at the end we would end up with a dataframe containing something like the following (120 raws for 120 songs, and as many columns as words):\n",
    "\n",
    "| | ah | adventure | ... | yeah \n",
    "|---|---|---|---|---| \n",
    "| 0 | 0 | 1 | ... | 4 |\n",
    "| 1 | 8 | 0 | ... | 2 |\n",
    "|...|...|...|...|...|\n",
    "| 119 | 5 | 0 | ... | 8 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2000' 'aaaaaah' 'aaaaah' 'aaaah' 'adventure' 'ah' 'ahh' 'ahhhh' 'aim'\n",
      " 'aiming' 'air' 'alive' 'alright' 'angel' 'animal' 'animals' 'answer'\n",
      " 'answers' 'anybody' 'apart' 'appear' 'arms' 'army' 'arrive' 'aside' 'ask'\n",
      " 'asleep' 'aterfall' 'atmosphere' 'attention' 'attitude' 'avoid' 'awake'\n",
      " 'away' 'ba' 'baby' 'backwards' 'bad' 'ball' 'baltimore' 'battle'\n",
      " 'beating' 'beautiful' 'beckon' 'beg' 'began' 'begin' 'beginning' 'begun'\n",
      " 'believe' 'believer' 'bells' 'belong' 'best' 'better' 'big' 'bigger'\n",
      " 'birds' 'bit' 'black' 'blame' 'bleed' 'blind' 'block' 'blood' 'blossom'\n",
      " 'blow' 'blue' 'body' 'bones' 'bono' 'boom' 'born' 'bought' 'boy' 'boys'\n",
      " 'break' 'breakdown' 'breaking' 'breath' 'bridge' 'bright' 'bring' 'broke'\n",
      " 'broken' 'brother' 'brothers' 'brought' 'brutality' 'bubble' 'bullet'\n",
      " 'burn' 'burning' 'burst' 'bursting' 'button' 'buy' 'cage' 'came' 'canvas'\n",
      " 'car' 'care' 'careful' 'carry' 'castle' 'catch' 'cathedrals' 'caught'\n",
      " 'cause' 'caused' 'chance' 'change' 'changing' 'chaos' 'chicken' 'choirs'\n",
      " 'choke' 'chorus' 'chris' 'christmas' 'circle' 'circumnavigate' 'city'\n",
      " 'clear' 'clearly' 'climb' 'cling' 'clocks' 'close' 'closed' 'closing'\n",
      " 'cloud' 'clouds' 'cold' 'colder' 'collapsible' 'color' 'colors' 'come'\n",
      " 'comes' 'coming' 'compares' 'complicated' 'concern' 'concrete'\n",
      " 'confidence' 'conquer' 'control' 'corner' 'cost' 'couldn' 'counting'\n",
      " 'course' 'covered' 'crawl' 'crocodiles' 'cross' 'crossed' 'cruel'\n",
      " 'crumble' 'crumbling' 'crying' 'cured' 'cut' 'cycle' 'dark' 'darkness'\n",
      " 'darling' 'dawn' 'day' 'daylight' 'days' 'dead' 'death' 'december'\n",
      " 'decide' 'deeper' 'defeat' 'degrees' 'demons' 'deny' 'deodorant'\n",
      " 'diamonds' 'did' 'didn' 'die' 'direction' 'disappear' 'discover'\n",
      " 'disposable' 'does' 'doesn' 'doing' 'don' 'doom' 'door' 'doubt'\n",
      " 'downtown' 'drag' 'draw' 'dream' 'dreaming' 'dreams' 'drew' 'drink'\n",
      " 'drive' 'drum' 'drunk' 'drunken' 'dry' 'dying' 'earth' 'easy'\n",
      " 'effortlessly' 'em' 'end' 'erodes' 'escape' 'everglow' 'everybody'\n",
      " 'expected' 'explain' 'explode' 'explodes' 'extra' 'eye' 'eyes' 'face'\n",
      " 'factory' 'fading' 'fall' 'falling' 'far' 'fast' 'faster' 'fate' 'father'\n",
      " 'favourite' 'fear' 'feel' 'feeling' 'feels' 'feet' 'fell' 'felt' 'field'\n",
      " 'fight' 'fighting' 'fine' 'fix' 'flame' 'flames' 'flew' 'flicker' 'float'\n",
      " 'floated' 'floating' 'floats' 'flock' 'flood' 'flow' 'flown' 'flows'\n",
      " 'fly' 'flying' 'follow' 'fool' 'forces' 'foreign' 'forever' 'forget'\n",
      " 'forgot' 'forgotten' 'forwards' 'fought' 'free' 'friend' 'friends' 'fun'\n",
      " 'fuss' 'future' 'gave' 'gets' 'ghost' 'girl' 'girls' 'gives' 'glass'\n",
      " 'glow' 'glowing' 'god' 'goddamn' 'goes' 'going' 'gold' 'golden' 'gone'\n",
      " 'gonna' 'good' 'got' 'gotta' 'grace' 'gravity' 'gray' 'green' 'ground'\n",
      " 'grown' 'guess' 'guide' 'gun' 'hands' 'hang' 'hard' 'hardest' 'harm'\n",
      " 'head' 'hear' 'heard' 'hears' 'heart' 'heaven' 'heavenly' 'heavy' 'heels'\n",
      " 'held' 'hello' 'help' 'hey' 'hide' 'high' 'highest' 'highway' 'hills'\n",
      " 'hit' 'hold' 'holding' 'hole' 'home' 'homes' 'honestly' 'honey' 'hoo'\n",
      " 'hope' 'hopeless' 'hoping' 'horizon' 'house' 'houses' 'hovering' 'human'\n",
      " 'hunting' 'hurt' 'hurts' 'hygiene' 'idiot' 'ignite' 'ill' 'innocence'\n",
      " 'innocent' 'inside' 'invisible' 'island' 'isn' 'jerusalem' 'just'\n",
      " 'keeping' 'key' 'kids' 'kind' 'king' 'kingdom' 'kisses' 'knees' 'knife'\n",
      " 'know' 'knows' 'la' 'ladder' 'lalalalala' 'land' 'landed' 'late' 'laugh'\n",
      " 'lay' 'lead' 'learn' 'leave' 'left' 'lengths' 'lens' 'let' 'lets'\n",
      " 'letting' 'lhuna' 'lie' 'lied' 'life' 'lifetime' 'lift' 'light' 'lighter'\n",
      " 'lightning' 'lights' 'like' 'line' 'lines' 'lining' 'lion' 'lips'\n",
      " 'listen' 'listening' 'little' 'live' 'lives' 'living' 'll' 'load'\n",
      " 'london' 'loneliness' 'lonely' 'long' 'look' 'looked' 'looking' 'loose'\n",
      " 'lord' 'lose' 'losing' 'lost' 'loud' 'loudest' 'love' 'loved' 'lovers'\n",
      " 'lovin' 'low' 'magic' 'make' 'makes' 'making' 'man' 'map' 'marianne'\n",
      " 'mark' 'mars' 'mast' 'matter' 'matters' 'maybe' 'mean' 'means' 'meant'\n",
      " 'medicine' 'meet' 'meeting' 'merry' 'mess' 'message' 'met' 'middle'\n",
      " 'miles' 'mind' 'minute' 'miracles' 'mirror' 'miss' 'missed' 'missing'\n",
      " 'missionaries' 'mistakes' 'moment' 'money' 'moon' 'morning' 'mother'\n",
      " 'mountain' 'mouth' 'movements' 'moves' 'moving' 'murder' 'music' 'near'\n",
      " 'nearer' 'need' 'neglected' 'nervous' 'new' 'night' 'noise' 'noose'\n",
      " 'number' 'ocean' 'ode' 'oh' 'ohh' 'okay' 'old' 'ones' 'ooh' 'ooooooh'\n",
      " 'oooooooh' 'open' 'opened' 'opportunity' 'outro' 'outside' 'oxygen'\n",
      " 'page' 'paid' 'pain' 'para' 'paradise' 'parting' 'past' 'patient' 'pay'\n",
      " 'peace' 'people' 'perfect' 'permanent' 'picket' 'picks' 'picture' 'piece'\n",
      " 'pillars' 'pilots' 'place' 'places' 'plan' 'plot' 'point' 'poison' 'poor'\n",
      " 'possibly' 'pour' 'power' 'pray' 'precious' 'pressure' 'price' 'princess'\n",
      " 'prize' 'promise' 'proof' 'pull' 'punish' 'purple' 'pushing' 'puzzle'\n",
      " 'quiet' 'race' 'radio' 'rain' 'raining' 'rainy' 'raise' 'ran' 'raw'\n",
      " 'reach' 'ready' 'realize' 'realized' 'really' 'reason' 'records'\n",
      " 'recycled' 'red' 'reflect' 'refrain' 'reign' 'release' 'remain'\n",
      " 'remember' 'remembers' 'replace' 'rescue' 'rest' 'revenge' 'rhymes'\n",
      " 'ride' 'right' 'ring' 'ringing' 'rips' 'rise' 'rising' 'risked' 'river'\n",
      " 'rivers' 'road' 'rock' 'rocket' 'rocks' 'roll' 'rolled' 'rollin'\n",
      " 'rolling' 'roman' 'rooftops' 'ropes' 'rose' 'round' 'rule' 'ruled' 'run'\n",
      " 'running' 'rush' 'safe' 'said' 'saint' 'saints' 'sake' 'salt' 'sand'\n",
      " 'sang' 'sat' 'satellites' 'save' 'saved' 'saving' 'saw' 'say' 'saying'\n",
      " 'says' 'scarecrow' 'scared' 'scarred' 'scene' 'screaming' 'sea' 'search'\n",
      " 'searching' 'seas' 'second' 'seconds' 'secret' 'secrets' 'seed' 'seeing'\n",
      " 'seen' 'seize' 'selling' 'send' 'sense' 'sent' 'separated' 'serenade'\n",
      " 'serene' 'set' 'sets' 'settle' 'seven' 'seventeen' 'shade' 'shadow'\n",
      " 'shadows' 'shape' 'share' 'shattered' 'shelf' 'shield' 'shine' 'shines'\n",
      " 'shining' 'ship' 'shiver' 'shoot' 'short' 'sick' 'sight' 'sign' 'silent'\n",
      " 'silver' 'simple' 'simultaneously' 'sin' 'sing' 'singing' 'single'\n",
      " 'sinking' 'sisters' 'sit' 'sitting' 'skies' 'skin' 'sky' 'sleep'\n",
      " 'sleeping' 'slow' 'slowly' 'smashed' 'smell' 'smile' 'smiling'\n",
      " 'smithereens' 'smoke' 'snapping' 'snow' 'soar' 'sold' 'soldier'\n",
      " 'soldiers' 'solid' 'somebody' 'son' 'song' 'songbird' 'songs' 'soon'\n",
      " 'sore' 'soul' 'sound' 'space' 'spark' 'sparkle' 'sparks' 'speed' 'spell'\n",
      " 'spend' 'spent' 'spider' 'spies' 'spoken' 'spray' 'spread' 'spun' 'stake'\n",
      " 'stand' 'standing' 'star' 'stare' 'stars' 'start' 'started' 'starting'\n",
      " 'starts' 'state' 'stay' 'stayed' 'stays' 'steal' 'step' 'stick' 'stole'\n",
      " 'stomach' 'stone' 'stones' 'stood' 'stop' 'stopping' 'stops' 'storm'\n",
      " 'stormy' 'stow' 'straight' 'stranger' 'strangers' 'strangest'\n",
      " 'strawberry' 'stray' 'streaming' 'streams' 'street' 'streetlights'\n",
      " 'streets' 'strike' 'strikes' 'string' 'strong' 'stronger' 'stuck'\n",
      " 'stumble' 'stupid' 'style' 'suffering' 'sugar' 'summer' 'sun' 'sung'\n",
      " 'sunlight' 'sunny' 'sunset' 'sure' 'surface' 'survive' 'swallowed' 'swam'\n",
      " 'swear' 'sweet' 'sweetest' 'swerve' 'swimming' 'swing' 'swirling'\n",
      " 'swirls' 'sword' 'symmetry' 'symphony' 'taken' 'taking' 'talk' 'talking'\n",
      " 'tangled' 'tanzaku' 'target' 'taste' 'tasted' 'tattoo' 'tear' 'teardrop'\n",
      " 'tearing' 'tears' 'teeth' 'telescope' 'televisions' 'tell' 'telling'\n",
      " 'temptation' 'tennessee' 'tense' 'thing' 'things' 'think' 'thinking'\n",
      " 'thinks' 'thirst' 'thirsty' 'thorn' 'thorns' 'thought' 'thousand' 'threw'\n",
      " 'throat' 'throw' 'throwing' 'thrown' 'thunder' 'tickets' 'ticking' 'tide'\n",
      " 'tides' 'tie' 'tied' 'ties' 'tiger' 'tight' 'tightrope' 'til' 'till'\n",
      " 'tilt' 'time' 'times' 'tin' 'tiny' 'tired' 'today' 'toe' 'toiling' 'told'\n",
      " 'tones' 'tongue' 'tonight' 'took' 'torn' 'torture' 'touch' 'town' 'towns'\n",
      " 'trace' 'tracks' 'train' 'trap' 'trapped' 'traveling' 'treasure'\n",
      " 'treasures' 'tree' 'trees' 'trench' 'tribute' 'tried' 'trouble'\n",
      " 'troubles' 'true' 'trust' 'truth' 'try' 'trying' 'tumbling' 'tune'\n",
      " 'tunnel' 'turn' 'turned' 'turning' 'turns' 'tv' 'twice' 'twin' 'twist'\n",
      " 'uh' 'umi' 'unchanged' 'underground' 'underneath' 'understand' 'undone'\n",
      " 'unite' 'universe' 'untrue' 'use' 'used' 've' 'verse' 'vest' 'view'\n",
      " 'violent' 'violet' 'voice' 'wa' 'wait' 'waited' 'waiting' 'waits' 'wake'\n",
      " 'waking' 'walk' 'walking' 'walks' 'wall' 'walls' 'wanna' 'want' 'wanted'\n",
      " 'war' 'warm' 'warning' 'waste' 'watch' 'watching' 'water' 'waterfall'\n",
      " 'waters' 'waves' 'way' 'weapon' 'wears' 'web' 'weeping' 'weight' 'went'\n",
      " 'wheel' 'wheels' 'whisper' 'white' 'whoa' 'wild' 'win' 'wind' 'windows'\n",
      " 'winds' 'wine' 'wings' 'winner' 'winter' 'wire' 'wish' 'witches' 'woman'\n",
      " 'won' 'wonder' 'wonderful' 'woo' 'wooden' 'word' 'words' 'work' 'world'\n",
      " 'worn' 'worry' 'worse' 'worth' 'wouldn' 'wrapped' 'wreckage' 'write'\n",
      " 'written' 'wrong' 'wrote' 'x10' 'x15' 'x2' 'x7' 'ya' 'yeah' 'years'\n",
      " 'yellow' 'yes' 'yesterday' 'young']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000</th>\n",
       "      <th>aaaaaah</th>\n",
       "      <th>aaaaah</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>adventure</th>\n",
       "      <th>ah</th>\n",
       "      <th>ahh</th>\n",
       "      <th>ahhhh</th>\n",
       "      <th>aim</th>\n",
       "      <th>aiming</th>\n",
       "      <th>...</th>\n",
       "      <th>x15</th>\n",
       "      <th>x2</th>\n",
       "      <th>x7</th>\n",
       "      <th>ya</th>\n",
       "      <th>yeah</th>\n",
       "      <th>years</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     2000  aaaaaah  aaaaah  aaaah  adventure  ah  ahh  ahhhh  aim  aiming  \\\n",
       "0       0        0       0      0          0   0    0      0    0       0   \n",
       "1       0        0       0      0          0   0    0      0    0       0   \n",
       "2       0        0       0      0          0   0    0      0    0       0   \n",
       "3       0        0       0      0          0   0    0      0    0       0   \n",
       "4       0        0       0      0          0   0    0      0    0       0   \n",
       "..    ...      ...     ...    ...        ...  ..  ...    ...  ...     ...   \n",
       "115     0        0       0      0          0   0    0      0    0       0   \n",
       "116     0        0       0      0          0   0    0      0    0       0   \n",
       "117     0        0       0      0          0   0    0      0    0       0   \n",
       "118     0        0       0      0          0   0    0      0    0       0   \n",
       "119     0        0       0      0          0   0    0      0    0       0   \n",
       "\n",
       "     ...  x15  x2  x7  ya  yeah  years  yellow  yes  yesterday  young  \n",
       "0    ...    0   0   0   0     0      0       0    0          0      0  \n",
       "1    ...    0   0   0   0     0      0       0    0          0      0  \n",
       "2    ...    0   0   0   0     2      0       0    0          0      0  \n",
       "3    ...    0   0   0   0     2      0       0    0          0      0  \n",
       "4    ...    0   0   0   0     0      0       0    0          0      0  \n",
       "..   ...  ...  ..  ..  ..   ...    ...     ...  ...        ...    ...  \n",
       "115  ...    0   0   0   0     0      0       0    0          0      0  \n",
       "116  ...    0   0   0   0    11      0       0    0          0      0  \n",
       "117  ...    0   0   0   0     3      0       0    0          0      0  \n",
       "118  ...    0   0   0   0     0      0       0    0          0      0  \n",
       "119  ...    0   0   0   0     0      0       0    0          0      0  \n",
       "\n",
       "[120 rows x 1000 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Create a new dataframe containing the BOW outputs and the corresponding words as columns. And print it\n",
    "# df of BOW outputs for each song\n",
    "# Get the words associated to those numbers\n",
    "tokens = vectorizer.get_feature_names_out()\n",
    "print(f'tokens: {tokens}')\n",
    "\n",
    "# dataframe of BOW of all lyrics\n",
    "df_bow = pd.DataFrame(data=BOW, columns=tokens)\n",
    "df_bow\n",
    "# 120 rows : OK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well as you see we're still having some issue, we have some tokens that are not words, like '10' or '2000'.\n",
    "\n",
    "To get rid of that, we could use directly regular expressions within the function. Another solution would be to make preprocessing before using the function *CountVectorizer*.\n",
    "\n",
    "For the moment, we won't pay attention to this issue. But if you are curious and have time, you can find on google how to remove those words using the *CountVectorizer*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would like to see what are the most used words by Coldplay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oh      334\n",
       "don     190\n",
       "know    137\n",
       "just    136\n",
       "ll      132\n",
       "come    126\n",
       "yeah    111\n",
       "ooh      95\n",
       "love     95\n",
       "want     86\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## most used words: ATTENTION SANS PRE-PROCESSING ICI !\n",
    "df_bow.sum(axis=0).sort_values(ascending=False)[:10]\n",
    "\"\"\"\n",
    "oh      334\n",
    "don     190\n",
    "know    137\n",
    "just    136\n",
    "ll      132\n",
    "come    126\n",
    "yeah    111\n",
    "ooh      95\n",
    "love     95\n",
    "want     86\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what is the most used word? Are you surprised?\n",
    "\n",
    "Now make a sort in order to show the 10 most used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print the 10 most used word by Coldplay\n",
    "# voir ci-dessus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is! You know the Coldplay lyrics more than the singers now!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
